[
  {
    "id": 1,
    "question": "Which Spark component is responsible for scheduling tasks across the cluster?",
    "choices": [
      "Spark Driver",
      "Executor",
      "Cluster Manager",
      "Shuffle Manager"
    ],
    "correct": 0,
    "description": "The Driver orchestrates execution by turning jobs into stages and tasks and coordinating work distribution across executors."
  },
  {
    "id": 2,
    "question": "In Spark, what is the role of Executors?",
    "choices": [
      "Store application metadata",
      "Run tasks and store data in memory or disk",
      "Monitor job metrics",
      "Provide a web UI for Spark cluster"
    ],
    "correct": 1,
    "description": "Executors are worker processes responsible for executing tasks and caching/shuffling data."
  },
  {
    "id": 3,
    "question": "What is the smallest unit of parallel execution in Spark?",
    "choices": [
      "Job",
      "Stage",
      "Task",
      "Partition"
    ],
    "correct": 2,
    "description": "A task is executed on a partition of data, making it the smallest schedulable unit."
  },
  {
    "id": 4,
    "question": "A Spark Job is divided into Stages based on:",
    "choices": [
      "Number of input files",
      "Number of RDD transformations",
      "Shuffle boundaries",
      "Cluster size"
    ],
    "correct": 2,
    "description": "Stages are formed when a shuffle transformation (like reduceByKey) requires data redistribution."
  },
  {
    "id": 5,
    "question": "Which phase describes how Spark recovers RDD data on node failure?",
    "choices": [
      "DataFrame Optimization",
      "Lazy Evaluation",
      "Lineage-Based Fault Tolerance",
      "Task Serialization"
    ],
    "correct": 2,
    "description": "Spark uses DAG lineage to recompute only missing partitions, allowing fast recovery without replication."
  },
  {
    "id": 6,
    "question": "Which component tracks resource allocation and can manage multiple Spark applications?",
    "choices": [
      "Executor",
      "Cluster Manager",
      "Driver Web UI",
      "DAG Scheduler"
    ],
    "correct": 1,
    "description": "Cluster managers like YARN, Mesos, or Kubernetes allocate resources and manage multiple workloads."
  },
  {
    "id": 7,
    "question": "Which Scheduler converts a logical job to stages?",
    "choices": [
      "Task Scheduler",
      "DAG Scheduler",
      "Shuffle Scheduler",
      "Cluster Scheduler"
    ],
    "correct": 1,
    "description": "DAG Scheduler identifies shuffle boundaries and splits a job into stages for execution."
  },
  {
    "id": 8,
    "question": "Which Spark scheduling layer assigns tasks to executors?",
    "choices": [
      "DAG Scheduler",
      "Task Scheduler",
      "Cluster Manager",
      "Query Planner"
    ],
    "correct": 1,
    "description": "The Task Scheduler sends tasks to executors based on cluster availability."
  },
  {
    "id": 9,
    "question": "Which of the following improves data locality in Spark scheduling?",
    "choices": [
      "Task Serialization",
      "Speculative Execution",
      "Using broadcast variables",
      "Rack awareness"
    ],
    "correct": 3,
    "description": "Rack-aware scheduling ensures tasks run closer to the data, reducing network traffic."
  },
  {
    "id": 10,
    "question": "When does Spark build the physical execution plan?",
    "choices": [
      "As soon as transformations are applied",
      "Only during an action",
      "During driver startup",
      "After the shuffle operation"
    ],
    "correct": 1,
    "description": "Spark uses lazy evaluation: execution planning begins when an action is triggered."
  },
  {
    "id": 11,
    "question": "What does the Spark Driver maintain during execution?",
    "choices": [
      "RDD cache storage",
      "The DAG, task status & metadata",
      "Input data partitions",
      "Checkpoint files"
    ],
    "correct": 1,
    "description": "The driver maintains job metadata, schedules tasks, and monitors status updates."
  },
  {
    "id": 12,
    "question": "What happens if a Spark Driver fails?",
    "choices": [
      "Executors continue working",
      "Another executor becomes driver",
      "Application fails unless recovery mechanism exists",
      "Stages restart automatically"
    ],
    "correct": 3,
    "description": "Without high availability, driver failure results in application failure; HA mode enables recovery."
  },
  {
    "id": 13,
    "question": "Which memory area in Spark is used for caching RDD/DataFrame data?",
    "choices": [
      "Execution Memory",
      "Storage Memory",
      "Heap Memory",
      "Off-heap Memory"
    ],
    "correct": 1,
    "description": "Storage memory is reserved for caching user data and shuffle blocks."
  },
  {
    "id": 14,
    "question": "Speculative execution is used when:",
    "choices": [
      "Partitions are too large",
      "Tasks are running slower than expected",
      "The driver is overloaded",
      "Executors are idle"
    ],
    "correct": 1,
    "description": "Slow tasks (stragglers) may be executed redundantly on another executor to speed job completion."
  },
  {
    "id": 15,
    "question": "Which is true about shuffle in Spark?",
    "choices": [
      "Shuffles increase parallelism with no overhead",
      "Shuffle writes intermediate data to disk",
      "Shuffle operations are transformations",
      "Shuffles eliminate wide dependencies"
    ],
    "correct": 1,
    "description": "Shuffle involves disk & network operations, and creates wide dependencies causing stage boundaries."
  },
  {
    "id": 16,
    "question": "Broadcast variables help performance when:",
    "choices": [
      "Broadcasting large datasets",
      "Small lookup data needs to be available on all executors",
      "Sharing data between tasks on same executor",
      "Data needs checkpointing"
    ],
    "correct": 1,
    "description": "Broadcast variables avoid repeated data transfer by distributing small read-only data once per executor."
  },
  {
    "id": 17,
    "question": "What is the role of the Shuffle Manager?",
    "choices": [
      "Optimizing DataFrame queries",
      "Tracking cached data",
      "Coordinating data exchange between executors",
      "Logging job progress"
    ],
    "correct": 2,
    "description": "Shuffle Manager handles mapping, sorting, and transferring intermediate shuffled data."
  },
  {
    "id": 18,
    "question": "Which component persists shuffle files?",
    "choices": [
      "Driver",
      "Executor Local Storage",
      "Cluster Manager",
      "Checkpoint Directory"
    ],
    "correct": 1,
    "description": "Shuffle data is stored locally on executor disks during a stage and fetched when required."
  },
  {
    "id": 19,
    "question": "Why are narrow dependencies faster in Spark?",
    "choices": [
      "They always use in-memory execution",
      "They avoid shuffles",
      "They use optimized serialization",
      "They increase data skew"
    ],
    "correct": 1,
    "description": "Narrow dependencies allow pipelined execution within same partition without shuffling."
  },
  {
    "id": 20,
    "question": "Data skew occurs when:",
    "choices": [
      "Partitions are evenly distributed",
      "Tasks are killed by driver",
      "Some partitions contain significantly more data than others",
      "Executors fail"
    ],
    "correct": 2,
    "description": "Uneven key distribution causes some tasks to take longer, slowing overall execution."
  },
  {
    "id": 21,
    "question": "Which memory category in Spark stores temporary intermediate results for tasks?",
    "choices": [
      "Storage Memory",
      "Execution Memory",
      "Static Heap Memory",
      "Reserve Memory"
    ],
    "correct": 1,
    "description": "Execution memory is used for shuffles, sorting, joins, and aggregations."
  },
  {
    "id": 22,
    "question": "Why does Spark use event logs?",
    "choices": [
      "To store input data",
      "To replay job history in the Spark history server",
      "To recover RDD lineage",
      "To perform SQL optimization"
    ],
    "correct": 1,
    "description": "Event logs help visualize and debug completed jobs using the History Server."
  },
  {
    "id": 23,
    "question": "In Spark architecture, which component runs inside worker nodes?",
    "choices": [
      "Driver",
      "Executors",
      "Cluster Manager",
      "DAG Scheduler"
    ],
    "correct": 1,
    "description": "Executors are launched on worker nodes to execute tasks."
  },
  {
    "id": 24,
    "question": "Which technique helps avoid expensive recomputation for long RDD lineages?",
    "choices": [
      "Checkpointing",
      "More executors",
      "More tasks per stage",
      "Higher shuffle partitions"
    ],
    "correct": 0,
    "description": "Checkpointing truncates lineage by saving RDD to reliable storage like HDFS."
  },
  {
    "id": 25,
    "question": "Which scenario triggers stage retries?",
    "choices": [
      "Driver memory spill",
      "Failure of tasks within the stage",
      "Slow shuffle fetch",
      "Speculative execution enabled"
    ],
    "correct": 1,
    "description": "Any task failure in a stage results in the stage being retried depending on configuration."
  },
  {
    "id": 26,
    "question": "Spark's cluster mode typically runs the Driver on:",
    "choices": [
      "Userâ€™s laptop",
      "A random worker node",
      "Master node / cluster manager node",
      "History server"
    ],
    "correct": 2,
    "description": "In cluster mode, the driver runs inside the cluster (usually on a designated master node)."
  },
  {
    "id": 27,
    "question": "Which feature helps in rebalancing data across partitions to reduce skew?",
    "choices": [
      "salting keys",
      "reduceByKey",
      "pipelining",
      "broadcast joins"
    ],
    "correct": 0,
    "description": "Salting spreads hot keys across multiple partitions to avoid straggler tasks."
  },
  {
    "id": 28,
    "question": "Which option best describes a wide dependency?",
    "choices": [
      "Each parent partition contributes to only one child partition",
      "Requires shuffle because child depends on many parents",
      "Cache must be enabled",
      "Always faster than narrow dependency"
    ],
    "correct": 1,
    "description": "Wide dependencies occur when many parent partitions feed a child partition, causing shuffle and stage boundaries."
  },
  {
    "id": 29,
    "question": "Which join type can commonly lead to data skew?",
    "choices": [
      "Range join",
      "Broadcast join",
      "Shuffle hash join",
      "Local join"
    ],
    "correct": 2,
    "description": "Shuffle joins redistribute data by key, which may overload partitions with popular keys."
  },
  {
    "id": 30,
    "question": "What happens when Spark executors are dynamically allocated?",
    "choices": [
      "Executors are pre-allocated for full job duration",
      "Executors scale up/down depending on workload",
      "Driver allocates memory from disk",
      "Tasks are merged into fewer stages"
    ],
    "correct": 1,
    "description": "Dynamic allocation allows Spark to adjust resource usage to optimize cost and performance."
  }
]
