[
  {
    "id": 1,
    "question": "What is the primary goal of Spark's Unified Memory Manager (Spark 1.6+)?",
    "choices": [
      "To separate execution and storage memory strictly",
      "To dynamically share memory between execution (shuffle) and storage (caching)",
      "To offload all memory to disk",
      "To allocate all memory to the driver"
    ],
    "correct": 1,
    "description": "Unified Memory Manager (Tungsten) allows **execution** (shuffle, joins) and **storage** (cached RDDs) to **borrow** from each other.\n- Config: `spark.memory.fraction` (default 0.6) = unified region\n- `spark.memory.storageFraction` (default 0.5) = initial storage share\n**Tuning Tip**: Lower `storageFraction` if you cache less, shuffle more. Monitor 'Storage Memory' in Spark UI."
  },
  {
    "id": 2,
    "question": "When does Spark spill to disk during shuffle write?",
    "choices": [
      "When shuffle buffer exceeds `spark.shuffle.file.buffer`",
      "Only when executor JVM heap is full",
      "When `spark.memory.fraction` is breached",
      "Never — always in memory"
    ],
    "correct": 0,
    "description": "Each shuffle map task has an in-memory buffer (`spark.shuffle.file.buffer`, default 32KB).\nWhen full → **spills to disk**.\nMultiple spills → merged later.\n**Tuning Tip**: Increase buffer to 64KB–128KB. Use SSDs. Monitor 'Shuffle Spill (Memory)' vs 'Spill (Disk)' in Spark UI."
  },
  {
    "id": 3,
    "question": "What is the correct order of memory regions in Spark's memory model?",
    "choices": [
      "Reserved → User → Execution → Storage",
      "Reserved → Execution + Storage (Unified) → User",
      "Execution → Storage → Reserved → User",
      "User → Execution → Storage → Reserved"
    ],
    "correct": 1,
    "description": "Spark executor memory layout:\n1. **Reserved** (300MB) — JVM overhead\n2. **Spark Memory** (`spark.memory.fraction` × heap) — **Unified** for:\n   - Execution (shuffle, joins)\n   - Storage (cached blocks)\n3. **User Memory** — your code, UDFs, internal structures\n**Tuning Tip**: Set `--executor-memory` ≥ 8GB, leave 10% for OS."
  },
  {
    "id": 4,
    "question": "How does off-heap memory (Tungsten) improve performance?",
    "choices": [
      "Avoids JVM GC pauses",
      "Stores shuffle data in heap",
      "Increases serialization overhead",
      "Only for driver"
    ],
    "correct": 0,
    "description": "Off-heap (direct memory):\n- Managed by Spark, not JVM GC\n- Used for cached data, shuffle (optional)\n- Reduces GC pressure\nEnable: `spark.memory.offHeap.enabled=true`, `spark.memory.offHeap.size`\n**Tuning Tip**: Use with Kryo + whole-stage codegen. Monitor via `jmap -histo` or Spark UI."
  },
  {
    "id": 5,
    "question": "What is data skew and how does AQE handle it (Spark 3+)?",
    "choices": [
      "Even data distribution",
      "AQE splits skewed partitions at runtime",
      "AQE increases shuffle partitions",
      "AQE uses broadcast for skew"
    ],
    "correct": 1,
    "description": "Skew: one key has >> others → straggler task.\n**AQE Skew Join**:\n- Detects skew during shuffle\n- **Splits large partition** into sub-partitions\n- Redistributes to idle executors\nEnabled: `spark.sql.adaptive.skewJoin.enabled=true`\n**Tuning Tip**: Combine with `spark.sql.adaptive.coalescePartitions.enabled`."
  },
  {
    "id": 6,
    "question": "What does Adaptive Query Execution (AQE) dynamically coalesce?",
    "choices": [
      "Input files",
      "Post-shuffle partitions",
      "Executor count",
      "Cached RDDs"
    ],
    "correct": 1,
    "description": "After shuffle, if partitions are tiny → **overhead**.\nAQE **coalesces small partitions** into fewer, larger ones.\nReduces task launch overhead.\nEnabled: `spark.sql.adaptive.coalescePartitions.enabled=true`\n**Tuning Tip**: Set `spark.sql.adaptive.coalescePartitions.minPartitionSize` (default 1MB)."
  },
  {
    "id": 7,
    "question": "When should you enable dynamic allocation?",
    "choices": [
      "Fixed workload",
      "Variable workload, shared cluster",
      "Standalone mode only",
      "Single job"
    ],
    "correct": 1,
    "description": "Dynamic Allocation:\n- Adds/removes executors based on pending tasks\n- Saves resources in shared clusters\nConfig:\n```properties\nspark.dynamicAllocation.enabled=true\nspark.dynamicAllocation.minExecutors=1\nspark.dynamicAllocation.maxExecutors=50\n```\n**Tuning Tip**: Use with `spark.shuffle.service.enabled=true` (external shuffle service)."
  },
  {
    "id": 8,
    "question": "What is the external shuffle service and why is it required for dynamic allocation?",
    "choices": [
      "Runs on driver",
      "Keeps shuffle files after executor removal",
      "Manages driver memory",
      "Handles SQL queries"
    ],
    "correct": 1,
    "description": "When executor is removed, its shuffle files are lost → **recompute**.\n**External Shuffle Service** (runs on NodeManager):\n- Persists shuffle files\n- Serves them to new executors\nRequired for dynamic allocation.\n**Tuning Tip**: Enable in YARN: `spark.shuffle.service.enabled=true`."
  },
  {
    "id": 9,
    "question": "What is the risk of setting `spark.sql.shuffle.partitions` too high?",
    "choices": [
      "Too much shuffle",
      "Too many small tasks → overhead",
      "OOM on driver",
      "No effect"
    ],
    "correct": 1,
    "description": "High partitions → many tiny tasks:\n- Task launch overhead\n- More shuffle files\n- GC pressure\n**Tuning Tip**: Target **100–200 MB per partition**. Use AQE to auto-coalesce."
  },
  {
    "id": 10,
    "question": "How to detect GC issues in Spark?",
    "choices": [
      "SQL tab",
      "Executors tab → GC Time",
      "Stages tab → Input size",
      "Environment tab"
    ],
    "correct": 1,
    "description": "In **Executors tab**:\n- **GC Time** > 10% of task time → problem\n- Frequent Full GC → OOM risk\n**Tuning Tip**: Use G1GC (`-XX:+UseG1GC`), increase executor memory, reduce object creation."
  },
  {
    "id": 11,
    "question": "What is speculative execution?",
    "choices": [
      "Running tasks faster",
      "Launching duplicate tasks for stragglers",
      "Predicting shuffle size",
      "Speculating data types"
    ],
    "correct": 1,
    "description": "If a task runs > 1.5× median → **speculative copy** launched.\nFirst result wins.\nHelps with stragglers (slow nodes, skew).\nEnable: `spark.speculation=true`\n**Tuning Tip**: Set `spark.speculation.multiplier`, `spark.speculation.quantile`."
  },
  {
    "id": 12,
    "question": "What is the best way to handle skewed keys manually?",
    "choices": [
      "Increase partitions",
      "Key salting + two-phase aggregation",
      "Use broadcast",
      "Reduce executor memory"
    ],
    "correct": 1,
    "description": "**Salting**:\n1. Append random suffix to skewed key\n2. Join/shuffle\n3. Aggregate within salt groups\n4. Final aggregate by original key\n**Tuning Tip**: Use with `explode(array)` or `posexplode` for fixed salt range."
  },
  {
    "id": 13,
    "question": "What is the role of `spark.sql.adaptive.optimizer.enabled`?",
    "choices": [
      "Enables AQE",
      "Enables cost-based optimization",
      "Enables whole-stage codegen",
      "Disables Catalyst"
    ],
    "correct": 0,
    "description": "`spark.sql.adaptive.enabled=true` → enables **entire AQE framework**:\n- Dynamic coalesce\n- Skew join\n- Join strategy switch\n**Tuning Tip**: Always enable in Spark 3+. Monitor 'SQL' tab → 'Adaptive Spark Plan'."
  },
  {
    "id": 14,
    "question": "When does AQE switch from Shuffle Hash to Sort Merge Join?",
    "choices": [
      "When small table > threshold",
      "When build side too big for hash",
      "When keys are strings",
      "Never"
    ],
    "correct": 1,
    "description": "AQE monitors build side size.\nIf > `spark.sql.adaptive.maxShuffledHashJoinMemory` → switches to **Sort Merge**.\nAvoids OOM.\n**Tuning Tip**: Tune `spark.sql.adaptive.autoBroadcastJoinThreshold`."
  },
  {
    "id": 15,
    "question": "What is the impact of Kryo serialization?",
    "choices": [
      "Slower but smaller objects",
      "Faster and smaller than Java serialization",
      "Only for RDDs",
      "Increases GC"
    ],
    "correct": 1,
    "description": "Kryo:\n- **Faster** (10x) than Java serialization\n- **Smaller** serialized objects\n- Reduces shuffle spill, network I/O\nEnable:\n```properties\nspark.serializer=org.apache.spark.serializer.KryoSerializer\nspark.kryo.registrationRequired=true\n```\n**Tuning Tip**: Register custom classes."
  },
  {
    "id": 16,
    "question": "How to reduce shuffle write size?",
    "choices": [
      "Use more partitions",
      "Filter and project early",
      "Use collect()",
      "Increase memory"
    ],
    "correct": 1,
    "description": "**Push down** filters and select only needed columns **before** shuffle.\nExample:\n```sql\nSELECT user_id, SUM(amount) FROM transactions WHERE date > '2025' GROUP BY user_id\n```\n**Tuning Tip**: Use `df.select(...).filter(...)` before `groupBy`."
  },
  {
    "id": 17,
    "question": "What is the purpose of `spark.sql.files.maxPartitionBytes`?",
    "choices": [
      "Max file size",
      "Max bytes per input split",
      "Max shuffle partition",
      "Max broadcast size"
    ],
    "correct": 1,
    "description": "Controls **input split size** when reading files.\nDefault: 128MB\nToo small → too many tasks\nToo large → memory pressure\n**Tuning Tip**: Set to 256MB–1GB for large Parquet files on fast storage."
  },
  {
    "id": 18,
    "question": "What is the best practice for caching?",
    "choices": [
      "Cache everything",
      "Cache only reused DataFrames with MEMORY_AND_DISK",
      "Cache on driver",
      "Use persist() always"
    ],
    "correct": 1,
    "description": "Cache **only reused** DataFrames.\nUse `MEMORY_AND_DISK` to spill safely.\n```scala\nval df = spark.read.parquet(...).cache()\n// or\ndf.persist(StorageLevel.MEMORY_AND_DISK)\n```\n**Tuning Tip**: Monitor 'Storage' tab. Use `df.unpersist()` after use."
  },
  {
    "id": 19,
    "question": "How to diagnose executor OOM?",
    "choices": [
      "Check driver logs",
      "Spark UI → Executors → 'RDD Blocks'",
      "Stages tab → 'Tasks'",
      "SQL tab"
    ],
    "correct": 1,
    "description": "OOM symptoms:\n- Tasks fail with 'java.lang.OutOfMemoryError'\n- High GC time\n**Diagnosis**:\n1. Spark UI → Executors → **'Memory Used'** near limit\n2. **'Shuffle Spill'** high\n3. Logs: 'ExecutorLost', 'GC overhead limit'\n**Tuning Tip**: Increase executor memory, reduce partition size, use off-heap."
  },
  {
    "id": 20,
    "question": "What is the optimal executor configuration?",
    "choices": [
      "1 executor per node",
      "5 cores, 15–25 GB RAM per executor",
      "1 core per executor",
      "100 GB per executor"
    ],
    "correct": 1,
    "description": "**Rule of Thumb**:\n- **5 cores** per executor (1 for daemon, 4 for tasks)\n- **15–25 GB RAM** (75% of node memory)\n- **1 executor per node** (YARN)\nAvoids HDFS/network contention.\n**Tuning Tip**: Use `spark.executor.cores`, `spark.executor.memory`, `spark.yarn.executor.memoryOverhead`."
  }
]